---
title: "p8105_hw3_hs3393"
author: "Haochen Sun"
date: "2022-10-06"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


### Loading packages
```{r, message = FALSE}
library(tidyverse)
library(ggplot2)
library(p8105.datasets)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


## Problem 1

```{r}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

#### Answer questions about the data

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, there are 134 aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles are ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, and includes the number of times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```


## Problem 2

```{r, message=FALSE}
data <- read_csv("data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minute", 
               names_prefix = "activity_",
               values_to = "activity_num") %>% 
  mutate(minute = as.numeric(minute)) %>% 
  mutate(wknd = if_else(
    day == "Sunday" | day == "Saturday", 
          true = "weekend", false = "weekday")) %>% 
  mutate(week = as.factor(week)) %>% 
  mutate(day_id = as.factor(day_id)) %>% 
  mutate(day = forcats::fct_relevel(day, 
        c("Monday", "Tuesday", "Wednesday","Thursday", "Friday",
          "Saturday", "Sunday"))
         ) %>% 
  mutate(wknd = forcats::fct_relevel(wknd, 
        c("weekday", "weekend")))
```

The variables in the dataset include: week, indicating in which week the data is collected. day_id, showing on which day during the 35 days experiment the data is collected. Day variable shows what the associate day is in a week. Minute means the data collecting time in one day start from midnight. Activity num shows the number of activities detected during the observation period. Wknd is a binary variable indicating whether or not the associate day be weekday or weekend.

There are `r nrow(data)` observations in the dataset and `r ncol(data)` variables.

## Generating tables

```{r table}
data %>% 
  group_by(day_id) %>% 
  summarise(sum_act = sum(activity_num)) %>% 
  knitr::kable(digits = 1)
```

No obvious trend is observed based on only day_id.

#### Generating plots

```{r plot}
data %>%
  ggplot(aes(x = minute, y = activity_num, color = day)) +
  geom_point(alpha = .3) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  labs(x = "Minute",
       y = "Activity Number",
       title = "Activity numbers throught out adays") + 
  viridis::scale_color_viridis(
    name = "day",
    discrete = TRUE
  )
```

The activity have some patterns: 1) Most of the time, the activity numbers in one minute is less than 2,500. 2) There are some peaks of activity number. The peaks are  at 450 minutes (7:30 am), 600 minutes (10:00 am), 1000 minutes(4:30 pm) 1250 minutes (8: 50 pm). The activity number in the midnight (0:00 am - 4:30 am) is the lowest in one day.


## Problem 3

```{r}
data("ny_noaa")
head(ny_noaa)
```

The dataset describes the weather data of New York collected by NOAA National Climatic Data Center. The dataset includes: id, showing the weather station ID. Date, shows the date of observation. Prcp: pricipitation (tenths of mm). Snow: snowfall (mm). Snwd: snow depth. Tmax: maximum temperature (tenths of degree). Tmin: minimum temperature (tenths of degree).

The size of the dataset is `r nrow(ny_noaa)` rows * `r ncol(ny_noaa)`. The proportion of NA in the last five columns (which contains numeric data) is `r round(sum(is.na(ny_noaa))/(5*nrow(ny_noaa)), digits = 4)`. So more than 25% data is NA, that's a severe problem.

#### Data cleaning
```{r}
datany <- ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-", remove = T) %>% 
  mutate_at(c("tmax", "tmin"), as.numeric) %>% 
  mutate(tmax = tmax / 10,
         tmin = tmin / 10,
         prcp = prcp / 10)

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate
    (match(v, uniqv)))]
}

getmode(pull(datany, snow))
```

The most commonly observed value is 0, because for most of the time in a year, it will not snow (except winter),

```{r}

data1_7 <- datany %>% 
  filter(month == "01" | month == "07") %>% 
  group_by(id, year ,month) %>% 
  summarize(ave_max = mean(tmax))

data1_7 %>% 
  ggplot(aes(x = year, y = ave_max, color = month)) +
  geom_boxplot() +
  facet_grid(. ~ month) + 
  labs(x = "Year",
       y = "Average maximum temperature (˚C)", 
    title = "Average max temperature in Januaray and July") + 
  scale_x_discrete(breaks = c("1985", "1990", "1995", 
    "2000", "2005", "2010"))

data1_7 %>% 
  ggplot(aes(x = year, y = ave_max, group = id,color = month)) +
  geom_line(alpha = .4) +
  facet_grid(. ~ month) + 
  labs(x = "Year",
       y = "Average maximum temperature (˚C)", 
    title = "Average max temperature in Januaray and July") + 
  scale_x_discrete(breaks = c("1985", "1990", "1995", 
    "2000", "2005", "2010"))
  
```

(To see the pattern clearer, I created another line plot for this problem) We can see that the variation of tmax in January is larger than that in July. There are highs and lows of the maximum temperature throughout history. The highest temperature in the summer and winter in the past 30 years does not change significantly. There are to some extend some outliers. Januaray have outliers higher and lower than normal, and for July, most of the outliers are lower than average. 


```{r fig.height = 5}
p_minmax = datany %>% 
  select(tmax, tmin) %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() +
  scale_fill_viridis_c()+
  guides(fill = guide_colourbar(barwidth = 10,   barheight = 0.7)) + 
  labs(title = "Tmax vs Tmin",
       xlab = "Max Temperature (˚C)",
       ylab = "Min Temperature (˚C)")

p_snow = datany %>% 
  filter(snow > 0 & snow < 100) %>% 
  ggplot(aes(x = year, y = snow)) +
  geom_boxplot() + 
  labs(x = "Year", 
       y = "Snow Fall (mm)",
       title = "Snowfall in each year") +
  scale_x_discrete(breaks = c("1981","1985", "1990", "1995", 
    "2000", "2005", "2010"))
  
p_merge = p_minmax + p_snow

p_merge
```


